{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Sequential,Model,initializers,layers,Input\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1257 files belonging to 10 classes.\n",
      "Using 1132 files for training.\n",
      "Found 1257 files belonging to 10 classes.\n",
      "Using 125 files for validation.\n"
     ]
    }
   ],
   "source": [
    "dir=r'D:\\dataset\\butterfly\\train'\n",
    "train_ds=tf.keras.preprocessing.image_dataset_from_directory(\n",
    "dir,\n",
    "labels=\"inferred\",\n",
    "label_mode=\"int\",\n",
    "class_names=None,\n",
    "color_mode=\"rgb\",\n",
    "batch_size=8,\n",
    "image_size=(299, 299),\n",
    "shuffle=True,\n",
    "seed=10,\n",
    "validation_split=0.1,\n",
    "subset='training',\n",
    "interpolation=\"gaussian\",\n",
    "follow_links=False,\n",
    "crop_to_aspect_ratio=False,)\n",
    "\n",
    "\n",
    "validation_ds=tf.keras.preprocessing.image_dataset_from_directory(\n",
    "dir,\n",
    "labels=\"inferred\",\n",
    "label_mode=\"int\",\n",
    "class_names=None,\n",
    "color_mode=\"rgb\",\n",
    "batch_size=8,\n",
    "image_size=(299, 299),\n",
    "shuffle=True,\n",
    "seed=10,\n",
    "validation_split=0.1,\n",
    "subset='validation',\n",
    "interpolation=\"gaussian\",\n",
    "follow_links=False,\n",
    "crop_to_aspect_ratio=False,)\n",
    "\n",
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255.)\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stem(input):\n",
    "    x=layers.Conv2D(filters=64,kernel_size=(7,7),strides=(2,2),padding='same',activation='relu')(input)\n",
    "    x=layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n",
    "    x=layers.LayerNormalization()(x)\n",
    "    x=layers.Conv2D(filters=192,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(x)\n",
    "    x=layers.Conv2D(filters=192,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')(x)\n",
    "    x=layers.LayerNormalization()(x)\n",
    "    x=layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)    \n",
    "    return x\n",
    "\n",
    "\n",
    "def Inception_Block(x,f1,f2,f3,f4,f5,f6):\n",
    "\n",
    "    x1=layers.Conv2D(filters=f1,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(x)\n",
    "          \n",
    "    x2=layers.Conv2D(filters=f2,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(x)\n",
    "    x2=layers.Conv2D(filters=f3,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')(x2)\n",
    "\n",
    "    x3=layers.Conv2D(filters=f4 ,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(x)\n",
    "    x3=layers.Conv2D(filters=f5,kernel_size=(5,5),strides=(1,1),padding='same',activation='relu')(x3)\n",
    "       \n",
    "    x4=layers.MaxPooling2D(pool_size=(3,3),strides=(1,1),padding='same')(x)\n",
    "    x4=layers.Conv2D(filters=f6,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(x4)\n",
    "    \n",
    "    return tf.concat([x1,x2,x3,x4],axis=3)\n",
    "\n",
    "def AUX1(input):\n",
    "    ax=layers.AveragePooling2D(pool_size=(1,1),strides=(1,1))(input)\n",
    "    ax=layers.Conv2D(filters=128,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(ax)\n",
    "    ax=layers.Flatten()(ax)\n",
    "    ax=layers.Dense(units=1024,activation='relu')(ax)\n",
    "    ax=layers.Dropout(0.7)(ax)\n",
    "    ax=layers.Dense(units=10,activation='softmax',name='ax1')(ax)\n",
    "    return ax\n",
    "\n",
    "def AUX2(input):\n",
    "    ax=layers.AveragePooling2D(pool_size=(1,1),strides=(1,1))(input)\n",
    "    ax=layers.Conv2D(filters=128,kernel_size=(1,1),strides=(1,1),padding='same',activation='relu')(ax)\n",
    "    ax=layers.Flatten()(ax)\n",
    "    ax=layers.Dense(units=1024,activation='relu')(ax)\n",
    "    ax=layers.Dropout(0.7)(ax)\n",
    "    ax=layers.Dense(units=10,activation='softmax',name='ax2')(ax)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def Classifier(input):\n",
    "    fc=layers.AveragePooling2D(pool_size=(7,7),strides=(1,1))(input)\n",
    "    fc=layers.Flatten()(fc)\n",
    "    fc=layers.Dense(units=10,activation='softmax',name='output')(fc)    \n",
    "    return fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=Input(shape=(299,299,3))\n",
    "x=Stem(inputs)\n",
    "x=Inception_Block(x,256,256,256,256,256,256)\n",
    "x=Inception_Block(x,480,480,480,480,480,480)\n",
    "x=layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n",
    "x=Inception_Block(x,512,512,512,512,512,512)\n",
    "\n",
    "ax1=AUX1(x)\n",
    "x=Inception_Block(x,512,512,512,512,512,512)\n",
    "x=Inception_Block(x,512,512,512,512,512,512)\n",
    "x=Inception_Block(x,528,528,528,528,528,528)\n",
    "\n",
    "ax2=AUX2(x)\n",
    "x=Inception_Block(x,832,832,832,832,832,832)\n",
    "x=layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n",
    "x=Inception_Block(x,832,832,832,832,832,832)\n",
    "x=Inception_Block(x,1024,1024,1024,1024,1024,1024)\n",
    "output=Classifier(x)\n",
    "   \n",
    "model = tf.keras.models.Model(inputs,[output,ax1,ax2],name = 'GoogleNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rate=tf.keras.optimizers.schedules.ExponentialDecay(1e-3, 10000, 0.97, staircase=False, name=None)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_rate),loss='sparse_categorical_crossentropy' ,metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_best_path=r'D:\\GitHub_repo\\CNN-Model-Application\\save_weights\\GoogleNet/'\n",
    "model_checkpoint_best=ModelCheckpoint(filepath=model_checkpoint_best_path,monitor='val_acc',save_best_only=True,save_weights_only=True,save_freq='epoch')\n",
    "early_stopping=EarlyStopping(monitor='val_acc',patience=30,min_delta=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "142/142 [==============================] - 102s 577ms/step - loss: 310.6987 - output_loss: 290.9084 - ax1_loss: 4.0030 - ax2_loss: 15.7873 - output_acc: 0.0963 - ax1_acc: 0.1025 - ax2_acc: 0.0936 - val_loss: 6.9022 - val_output_loss: 2.3076 - val_ax1_loss: 2.2975 - val_ax2_loss: 2.2970 - val_output_acc: 0.0880 - val_ax1_acc: 0.1440 - val_ax2_acc: 0.1440\n",
      "Epoch 2/50\n",
      "142/142 [==============================] - 75s 528ms/step - loss: 6.9185 - output_loss: 2.3066 - ax1_loss: 2.3100 - ax2_loss: 2.3020 - output_acc: 0.1113 - ax1_acc: 0.0919 - ax2_acc: 0.1016 - val_loss: 6.8893 - val_output_loss: 2.3012 - val_ax1_loss: 2.2950 - val_ax2_loss: 2.2931 - val_output_acc: 0.1440 - val_ax1_acc: 0.1440 - val_ax2_acc: 0.1440\n",
      "Epoch 3/50\n",
      "142/142 [==============================] - 76s 531ms/step - loss: 6.9196 - output_loss: 2.3086 - ax1_loss: 2.3083 - ax2_loss: 2.3027 - output_acc: 0.0963 - ax1_acc: 0.1148 - ax2_acc: 0.1131 - val_loss: 6.8874 - val_output_loss: 2.3023 - val_ax1_loss: 2.2929 - val_ax2_loss: 2.2922 - val_output_acc: 0.1440 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 4/50\n",
      "142/142 [==============================] - 73s 512ms/step - loss: 7.1436 - output_loss: 2.3980 - ax1_loss: 2.4144 - ax2_loss: 2.3312 - output_acc: 0.0928 - ax1_acc: 0.1042 - ax2_acc: 0.1034 - val_loss: 7.2982 - val_output_loss: 2.2981 - val_ax1_loss: 2.7097 - val_ax2_loss: 2.2905 - val_output_acc: 0.1440 - val_ax1_acc: 0.0640 - val_ax2_acc: 0.1200\n",
      "Epoch 5/50\n",
      "142/142 [==============================] - 82s 581ms/step - loss: 6.9580 - output_loss: 2.3072 - ax1_loss: 2.3248 - ax2_loss: 2.3261 - output_acc: 0.1034 - ax1_acc: 0.1016 - ax2_acc: 0.0963 - val_loss: 6.8850 - val_output_loss: 2.2980 - val_ax1_loss: 2.2907 - val_ax2_loss: 2.2962 - val_output_acc: 0.1200 - val_ax1_acc: 0.1440 - val_ax2_acc: 0.1200\n",
      "Epoch 6/50\n",
      "142/142 [==============================] - 77s 541ms/step - loss: 6.9473 - output_loss: 2.3056 - ax1_loss: 2.3024 - ax2_loss: 2.3394 - output_acc: 0.1034 - ax1_acc: 0.0981 - ax2_acc: 0.1034 - val_loss: 6.8785 - val_output_loss: 2.2965 - val_ax1_loss: 2.2898 - val_ax2_loss: 2.2922 - val_output_acc: 0.1440 - val_ax1_acc: 0.1440 - val_ax2_acc: 0.0640\n",
      "Epoch 7/50\n",
      "142/142 [==============================] - 66s 459ms/step - loss: 6.9065 - output_loss: 2.3016 - ax1_loss: 2.3023 - ax2_loss: 2.3026 - output_acc: 0.0892 - ax1_acc: 0.0928 - ax2_acc: 0.0998 - val_loss: 6.8727 - val_output_loss: 2.2941 - val_ax1_loss: 2.2898 - val_ax2_loss: 2.2888 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1440\n",
      "Epoch 8/50\n",
      "142/142 [==============================] - 77s 544ms/step - loss: 6.9053 - output_loss: 2.3007 - ax1_loss: 2.3012 - ax2_loss: 2.3034 - output_acc: 0.0972 - ax1_acc: 0.1148 - ax2_acc: 0.0954 - val_loss: 6.8701 - val_output_loss: 2.2927 - val_ax1_loss: 2.2892 - val_ax2_loss: 2.2882 - val_output_acc: 0.1200 - val_ax1_acc: 0.1440 - val_ax2_acc: 0.1440\n",
      "Epoch 9/50\n",
      "142/142 [==============================] - 77s 542ms/step - loss: 6.9028 - output_loss: 2.3004 - ax1_loss: 2.3010 - ax2_loss: 2.3013 - output_acc: 0.1095 - ax1_acc: 0.1060 - ax2_acc: 0.1095 - val_loss: 6.8717 - val_output_loss: 2.2922 - val_ax1_loss: 2.2890 - val_ax2_loss: 2.2905 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 10/50\n",
      "142/142 [==============================] - 77s 543ms/step - loss: 6.9046 - output_loss: 2.3005 - ax1_loss: 2.3007 - ax2_loss: 2.3035 - output_acc: 0.1095 - ax1_acc: 0.1087 - ax2_acc: 0.1016 - val_loss: 6.8695 - val_output_loss: 2.2916 - val_ax1_loss: 2.2886 - val_ax2_loss: 2.2892 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 11/50\n",
      "142/142 [==============================] - 78s 545ms/step - loss: 6.9006 - output_loss: 2.3002 - ax1_loss: 2.3010 - ax2_loss: 2.2994 - output_acc: 0.1095 - ax1_acc: 0.1051 - ax2_acc: 0.1007 - val_loss: 6.8660 - val_output_loss: 2.2904 - val_ax1_loss: 2.2880 - val_ax2_loss: 2.2876 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 12/50\n",
      "142/142 [==============================] - 77s 541ms/step - loss: 6.9063 - output_loss: 2.3002 - ax1_loss: 2.3039 - ax2_loss: 2.3022 - output_acc: 0.1095 - ax1_acc: 0.0936 - ax2_acc: 0.0875 - val_loss: 6.8700 - val_output_loss: 2.2907 - val_ax1_loss: 2.2885 - val_ax2_loss: 2.2908 - val_output_acc: 0.1200 - val_ax1_acc: 0.1440 - val_ax2_acc: 0.1200\n",
      "Epoch 13/50\n",
      "142/142 [==============================] - 76s 531ms/step - loss: 6.9049 - output_loss: 2.3001 - ax1_loss: 2.3016 - ax2_loss: 2.3032 - output_acc: 0.1095 - ax1_acc: 0.1007 - ax2_acc: 0.1166 - val_loss: 6.8695 - val_output_loss: 2.2904 - val_ax1_loss: 2.2888 - val_ax2_loss: 2.2903 - val_output_acc: 0.1200 - val_ax1_acc: 0.1440 - val_ax2_acc: 0.1200\n",
      "Epoch 14/50\n",
      "142/142 [==============================] - 77s 543ms/step - loss: 6.9043 - output_loss: 2.3000 - ax1_loss: 2.3015 - ax2_loss: 2.3029 - output_acc: 0.1095 - ax1_acc: 0.1007 - ax2_acc: 0.0998 - val_loss: 6.8680 - val_output_loss: 2.2900 - val_ax1_loss: 2.2886 - val_ax2_loss: 2.2894 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 15/50\n",
      "142/142 [==============================] - 78s 546ms/step - loss: 6.8994 - output_loss: 2.3000 - ax1_loss: 2.2998 - ax2_loss: 2.2996 - output_acc: 0.1095 - ax1_acc: 0.1095 - ax2_acc: 0.1016 - val_loss: 6.8654 - val_output_loss: 2.2896 - val_ax1_loss: 2.2879 - val_ax2_loss: 2.2879 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1440\n",
      "Epoch 16/50\n",
      "142/142 [==============================] - 78s 545ms/step - loss: 6.9036 - output_loss: 2.3002 - ax1_loss: 2.3006 - ax2_loss: 2.3029 - output_acc: 0.1095 - ax1_acc: 0.1113 - ax2_acc: 0.0883 - val_loss: 6.8664 - val_output_loss: 2.2896 - val_ax1_loss: 2.2880 - val_ax2_loss: 2.2888 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 17/50\n",
      "142/142 [==============================] - 69s 485ms/step - loss: 6.9061 - output_loss: 2.3000 - ax1_loss: 2.3023 - ax2_loss: 2.3039 - output_acc: 0.1095 - ax1_acc: 0.0963 - ax2_acc: 0.1007 - val_loss: 6.8664 - val_output_loss: 2.2893 - val_ax1_loss: 2.2875 - val_ax2_loss: 2.2896 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 18/50\n",
      "142/142 [==============================] - 76s 536ms/step - loss: 6.9006 - output_loss: 2.2999 - ax1_loss: 2.3002 - ax2_loss: 2.3005 - output_acc: 0.1095 - ax1_acc: 0.1157 - ax2_acc: 0.0945 - val_loss: 6.8656 - val_output_loss: 2.2892 - val_ax1_loss: 2.2870 - val_ax2_loss: 2.2894 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 19/50\n",
      "142/142 [==============================] - 76s 536ms/step - loss: 6.9029 - output_loss: 2.2998 - ax1_loss: 2.3001 - ax2_loss: 2.3030 - output_acc: 0.1095 - ax1_acc: 0.1131 - ax2_acc: 0.0989 - val_loss: 6.8666 - val_output_loss: 2.2892 - val_ax1_loss: 2.2877 - val_ax2_loss: 2.2897 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 20/50\n",
      "142/142 [==============================] - 76s 537ms/step - loss: 6.9025 - output_loss: 2.2999 - ax1_loss: 2.3016 - ax2_loss: 2.3011 - output_acc: 0.1095 - ax1_acc: 0.1060 - ax2_acc: 0.1025 - val_loss: 6.8640 - val_output_loss: 2.2888 - val_ax1_loss: 2.2869 - val_ax2_loss: 2.2883 - val_output_acc: 0.1200 - val_ax1_acc: 0.1440 - val_ax2_acc: 0.1440\n",
      "Epoch 21/50\n",
      "142/142 [==============================] - 76s 537ms/step - loss: 6.9010 - output_loss: 2.2999 - ax1_loss: 2.2997 - ax2_loss: 2.3014 - output_acc: 0.1095 - ax1_acc: 0.1051 - ax2_acc: 0.0989 - val_loss: 6.8646 - val_output_loss: 2.2887 - val_ax1_loss: 2.2878 - val_ax2_loss: 2.2881 - val_output_acc: 0.1200 - val_ax1_acc: 0.1440 - val_ax2_acc: 0.1440\n",
      "Epoch 22/50\n",
      "142/142 [==============================] - 77s 542ms/step - loss: 6.9030 - output_loss: 2.3002 - ax1_loss: 2.3013 - ax2_loss: 2.3016 - output_acc: 0.1069 - ax1_acc: 0.1007 - ax2_acc: 0.0981 - val_loss: 6.8643 - val_output_loss: 2.2889 - val_ax1_loss: 2.2874 - val_ax2_loss: 2.2880 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 23/50\n",
      "142/142 [==============================] - 78s 550ms/step - loss: 6.9013 - output_loss: 2.2998 - ax1_loss: 2.3010 - ax2_loss: 2.3005 - output_acc: 0.1095 - ax1_acc: 0.1025 - ax2_acc: 0.1113 - val_loss: 6.8651 - val_output_loss: 2.2885 - val_ax1_loss: 2.2883 - val_ax2_loss: 2.2883 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 24/50\n",
      "142/142 [==============================] - 77s 543ms/step - loss: 6.9011 - output_loss: 2.2997 - ax1_loss: 2.3005 - ax2_loss: 2.3009 - output_acc: 0.1095 - ax1_acc: 0.1007 - ax2_acc: 0.1175 - val_loss: 6.8657 - val_output_loss: 2.2884 - val_ax1_loss: 2.2885 - val_ax2_loss: 2.2889 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1440\n",
      "Epoch 25/50\n",
      "142/142 [==============================] - 76s 535ms/step - loss: 6.9008 - output_loss: 2.2997 - ax1_loss: 2.3003 - ax2_loss: 2.3008 - output_acc: 0.1095 - ax1_acc: 0.1148 - ax2_acc: 0.1210 - val_loss: 6.8644 - val_output_loss: 2.2882 - val_ax1_loss: 2.2882 - val_ax2_loss: 2.2880 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1440\n",
      "Epoch 26/50\n",
      "142/142 [==============================] - 77s 541ms/step - loss: 6.8993 - output_loss: 2.2998 - ax1_loss: 2.3005 - ax2_loss: 2.2990 - output_acc: 0.1060 - ax1_acc: 0.1175 - ax2_acc: 0.1042 - val_loss: 6.8636 - val_output_loss: 2.2881 - val_ax1_loss: 2.2884 - val_ax2_loss: 2.2871 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1440\n",
      "Epoch 27/50\n",
      "142/142 [==============================] - 77s 543ms/step - loss: 6.9005 - output_loss: 2.2997 - ax1_loss: 2.3012 - ax2_loss: 2.2997 - output_acc: 0.1095 - ax1_acc: 0.1104 - ax2_acc: 0.1051 - val_loss: 6.8651 - val_output_loss: 2.2880 - val_ax1_loss: 2.2886 - val_ax2_loss: 2.2885 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 28/50\n",
      "142/142 [==============================] - 78s 545ms/step - loss: 6.9011 - output_loss: 2.2997 - ax1_loss: 2.3017 - ax2_loss: 2.2997 - output_acc: 0.1095 - ax1_acc: 0.0972 - ax2_acc: 0.1078 - val_loss: 6.8654 - val_output_loss: 2.2878 - val_ax1_loss: 2.2895 - val_ax2_loss: 2.2881 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 29/50\n",
      "142/142 [==============================] - 78s 545ms/step - loss: 6.9056 - output_loss: 2.2997 - ax1_loss: 2.3021 - ax2_loss: 2.3038 - output_acc: 0.1095 - ax1_acc: 0.0936 - ax2_acc: 0.0998 - val_loss: 6.8661 - val_output_loss: 2.2875 - val_ax1_loss: 2.2898 - val_ax2_loss: 2.2889 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 30/50\n",
      "142/142 [==============================] - 78s 545ms/step - loss: 6.9015 - output_loss: 2.2997 - ax1_loss: 2.3013 - ax2_loss: 2.3005 - output_acc: 0.1095 - ax1_acc: 0.1078 - ax2_acc: 0.1016 - val_loss: 6.8680 - val_output_loss: 2.2878 - val_ax1_loss: 2.2899 - val_ax2_loss: 2.2902 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 31/50\n",
      "142/142 [==============================] - 78s 549ms/step - loss: 6.9025 - output_loss: 2.2997 - ax1_loss: 2.3008 - ax2_loss: 2.3019 - output_acc: 0.1095 - ax1_acc: 0.1078 - ax2_acc: 0.0954 - val_loss: 6.8658 - val_output_loss: 2.2874 - val_ax1_loss: 2.2885 - val_ax2_loss: 2.2899 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 32/50\n",
      "142/142 [==============================] - 78s 545ms/step - loss: 6.9021 - output_loss: 2.2997 - ax1_loss: 2.3014 - ax2_loss: 2.3010 - output_acc: 0.1095 - ax1_acc: 0.1051 - ax2_acc: 0.0981 - val_loss: 6.8661 - val_output_loss: 2.2876 - val_ax1_loss: 2.2891 - val_ax2_loss: 2.2893 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 33/50\n",
      "142/142 [==============================] - 77s 539ms/step - loss: 6.9026 - output_loss: 2.2997 - ax1_loss: 2.3001 - ax2_loss: 2.3027 - output_acc: 0.1034 - ax1_acc: 0.1104 - ax2_acc: 0.0936 - val_loss: 6.8653 - val_output_loss: 2.2876 - val_ax1_loss: 2.2882 - val_ax2_loss: 2.2895 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 34/50\n",
      "142/142 [==============================] - 77s 539ms/step - loss: 6.9013 - output_loss: 2.2998 - ax1_loss: 2.3002 - ax2_loss: 2.3014 - output_acc: 0.1095 - ax1_acc: 0.1166 - ax2_acc: 0.1042 - val_loss: 6.8646 - val_output_loss: 2.2874 - val_ax1_loss: 2.2879 - val_ax2_loss: 2.2893 - val_output_acc: 0.1200 - val_ax1_acc: 0.1440 - val_ax2_acc: 0.1200\n",
      "Epoch 35/50\n",
      "142/142 [==============================] - 76s 536ms/step - loss: 6.8984 - output_loss: 2.2997 - ax1_loss: 2.3002 - ax2_loss: 2.2985 - output_acc: 0.1095 - ax1_acc: 0.1042 - ax2_acc: 0.1219 - val_loss: 6.8639 - val_output_loss: 2.2874 - val_ax1_loss: 2.2878 - val_ax2_loss: 2.2887 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 36/50\n",
      "142/142 [==============================] - 78s 546ms/step - loss: 6.9020 - output_loss: 2.2997 - ax1_loss: 2.3010 - ax2_loss: 2.3012 - output_acc: 0.1095 - ax1_acc: 0.1007 - ax2_acc: 0.1095 - val_loss: 6.8632 - val_output_loss: 2.2873 - val_ax1_loss: 2.2880 - val_ax2_loss: 2.2880 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 37/50\n",
      "142/142 [==============================] - 79s 554ms/step - loss: 6.9028 - output_loss: 2.2997 - ax1_loss: 2.3012 - ax2_loss: 2.3019 - output_acc: 0.1095 - ax1_acc: 0.1034 - ax2_acc: 0.0945 - val_loss: 6.8653 - val_output_loss: 2.2876 - val_ax1_loss: 2.2893 - val_ax2_loss: 2.2885 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 38/50\n",
      "142/142 [==============================] - 79s 554ms/step - loss: 6.8998 - output_loss: 2.2997 - ax1_loss: 2.2992 - ax2_loss: 2.3009 - output_acc: 0.1095 - ax1_acc: 0.1078 - ax2_acc: 0.1060 - val_loss: 6.8641 - val_output_loss: 2.2874 - val_ax1_loss: 2.2885 - val_ax2_loss: 2.2881 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 39/50\n",
      "142/142 [==============================] - 78s 546ms/step - loss: 6.9003 - output_loss: 2.2997 - ax1_loss: 2.3002 - ax2_loss: 2.3004 - output_acc: 0.1095 - ax1_acc: 0.1104 - ax2_acc: 0.1254 - val_loss: 6.8663 - val_output_loss: 2.2878 - val_ax1_loss: 2.2893 - val_ax2_loss: 2.2892 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 40/50\n",
      "142/142 [==============================] - 78s 551ms/step - loss: 6.9025 - output_loss: 2.2997 - ax1_loss: 2.3007 - ax2_loss: 2.3021 - output_acc: 0.1095 - ax1_acc: 0.1051 - ax2_acc: 0.0963 - val_loss: 6.8656 - val_output_loss: 2.2875 - val_ax1_loss: 2.2886 - val_ax2_loss: 2.2895 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 41/50\n",
      "142/142 [==============================] - 79s 552ms/step - loss: 6.8986 - output_loss: 2.2997 - ax1_loss: 2.2993 - ax2_loss: 2.2997 - output_acc: 0.1095 - ax1_acc: 0.1042 - ax2_acc: 0.1193 - val_loss: 6.8649 - val_output_loss: 2.2875 - val_ax1_loss: 2.2889 - val_ax2_loss: 2.2885 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 42/50\n",
      "142/142 [==============================] - 78s 550ms/step - loss: 6.9015 - output_loss: 2.2997 - ax1_loss: 2.3018 - ax2_loss: 2.3000 - output_acc: 0.1095 - ax1_acc: 0.0981 - ax2_acc: 0.1140 - val_loss: 6.8631 - val_output_loss: 2.2872 - val_ax1_loss: 2.2882 - val_ax2_loss: 2.2876 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 43/50\n",
      "142/142 [==============================] - 76s 532ms/step - loss: 6.9009 - output_loss: 2.2997 - ax1_loss: 2.2999 - ax2_loss: 2.3013 - output_acc: 0.1095 - ax1_acc: 0.1184 - ax2_acc: 0.1113 - val_loss: 6.8639 - val_output_loss: 2.2872 - val_ax1_loss: 2.2883 - val_ax2_loss: 2.2884 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 44/50\n",
      "142/142 [==============================] - 77s 537ms/step - loss: 6.9014 - output_loss: 2.2997 - ax1_loss: 2.3012 - ax2_loss: 2.3005 - output_acc: 0.1095 - ax1_acc: 0.0954 - ax2_acc: 0.0989 - val_loss: 6.8656 - val_output_loss: 2.2874 - val_ax1_loss: 2.2889 - val_ax2_loss: 2.2892 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 45/50\n",
      "142/142 [==============================] - 77s 542ms/step - loss: 6.9025 - output_loss: 2.2997 - ax1_loss: 2.3016 - ax2_loss: 2.3012 - output_acc: 0.1095 - ax1_acc: 0.0981 - ax2_acc: 0.0857 - val_loss: 6.8653 - val_output_loss: 2.2875 - val_ax1_loss: 2.2887 - val_ax2_loss: 2.2891 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 46/50\n",
      "142/142 [==============================] - 77s 539ms/step - loss: 6.9005 - output_loss: 2.2997 - ax1_loss: 2.2997 - ax2_loss: 2.3012 - output_acc: 0.1095 - ax1_acc: 0.1193 - ax2_acc: 0.0963 - val_loss: 6.8644 - val_output_loss: 2.2875 - val_ax1_loss: 2.2888 - val_ax2_loss: 2.2882 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 47/50\n",
      "142/142 [==============================] - 77s 540ms/step - loss: 6.8993 - output_loss: 2.2997 - ax1_loss: 2.2996 - ax2_loss: 2.3000 - output_acc: 0.1060 - ax1_acc: 0.0928 - ax2_acc: 0.1069 - val_loss: 6.8641 - val_output_loss: 2.2873 - val_ax1_loss: 2.2886 - val_ax2_loss: 2.2882 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 48/50\n",
      "142/142 [==============================] - 77s 542ms/step - loss: 6.8996 - output_loss: 2.2997 - ax1_loss: 2.3001 - ax2_loss: 2.2998 - output_acc: 0.1095 - ax1_acc: 0.1095 - ax2_acc: 0.1016 - val_loss: 6.8638 - val_output_loss: 2.2873 - val_ax1_loss: 2.2888 - val_ax2_loss: 2.2877 - val_output_acc: 0.1200 - val_ax1_acc: 0.1440 - val_ax2_acc: 0.1440\n",
      "Epoch 49/50\n",
      "142/142 [==============================] - 78s 547ms/step - loss: 6.9012 - output_loss: 2.2997 - ax1_loss: 2.3010 - ax2_loss: 2.3004 - output_acc: 0.1095 - ax1_acc: 0.1228 - ax2_acc: 0.0998 - val_loss: 6.8637 - val_output_loss: 2.2872 - val_ax1_loss: 2.2889 - val_ax2_loss: 2.2876 - val_output_acc: 0.1200 - val_ax1_acc: 0.1200 - val_ax2_acc: 0.1200\n",
      "Epoch 50/50\n",
      "122/142 [========================>.....] - ETA: 10s - loss: 6.8965 - output_loss: 2.2984 - ax1_loss: 2.3002 - ax2_loss: 2.2978 - output_acc: 0.1096 - ax1_acc: 0.0953 - ax2_acc: 0.1199"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#train_ds?\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mfit(train_ds,validation_data\u001b[39m=\u001b[39;49mvalidation_ds,epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,batch_size\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m,verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\jin\\anaconda3\\envs\\Deep\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jin\\anaconda3\\envs\\Deep\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[0;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jin\\anaconda3\\envs\\Deep\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[1;32mc:\\Users\\jin\\anaconda3\\envs\\Deep\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[0;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jin\\anaconda3\\envs\\Deep\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[0;32m    342\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\Users\\jin\\anaconda3\\envs\\Deep\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     hook(batch, logs)\n\u001b[0;32m    390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\Users\\jin\\anaconda3\\envs\\Deep\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[1;32mc:\\Users\\jin\\anaconda3\\envs\\Deep\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   1158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\jin\\anaconda3\\envs\\Deep\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[1;32mc:\\Users\\jin\\anaconda3\\envs\\Deep\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\jin\\anaconda3\\envs\\Deep\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\jin\\anaconda3\\envs\\Deep\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    629\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mc:\\Users\\jin\\anaconda3\\envs\\Deep\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\jin\\anaconda3\\envs\\Deep\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   1124\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train_ds?\n",
    "history=model.fit(train_ds,validation_data=validation_ds,epochs=50,batch_size=8,verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f63f62229035d384e646c189fd217ceea058ae56feeee8d9eb8b5a7f24aaefef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
